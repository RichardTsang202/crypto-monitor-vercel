#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå®æ—¶ä¿¡å·ç›‘æ§è„šæœ¬
æ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—å’Œæ›´çµæ´»çš„å½¢æ€æ£€æµ‹é€»è¾‘
"""

import asyncio
import json
import pandas as pd
import numpy as np
import talib
from datetime import datetime, timedelta
import requests
from collections import deque
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import traceback
import hashlib
import hmac
import time
from urllib.parse import urlencode

# å¯¼å…¥é…ç½®
import os

# æ£€æµ‹è¿è¡Œç¯å¢ƒ
IS_HF_SPACE = os.getenv('SPACE_ID') is not None

# ç§»é™¤äº†symbol_updaterç›¸å…³å¯¼å…¥

try:
    if IS_HF_SPACE:
        try:
            from hf_config import DIVERGENCE_CONFIG, WEBHOOK_CONFIG, MONITORING_CONFIG, get_error_message_for_hf
        except ImportError:
            from realtime_config import DIVERGENCE_CONFIG, WEBHOOK_CONFIG, MONITORING_CONFIG
    else:
        from realtime_config import DIVERGENCE_CONFIG, WEBHOOK_CONFIG, MONITORING_CONFIG
except ImportError:
    # é»˜è®¤é…ç½®
    DIVERGENCE_CONFIG = {
        'macd': {'enabled': True, 'min_strength': 0.3},
        'rsi': {'enabled': True, 'min_strength': 5.0},
        'volume': {'enabled': True, 'min_strength': 0.2}
    }
    WEBHOOK_CONFIG = {
        'timeout': 10,
        'retry_attempts': 3,
        'retry_delay': 2
    }
    MONITORING_CONFIG = {
        'min_volume_24h': 20_000_000,
        'buffer_size': 144,
        'update_interval': 5
    }

# é…ç½®æ—¥å¿— - æ›´è¯¦ç»†çš„æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('monitor_debug.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class SignalData:
    """ä¿¡å·æ•°æ®ç»“æ„"""
    symbol: str
    timestamp: datetime
    price: float
    pattern_type: str
    trend_status: str
    macd_divergence: bool
    rsi_divergence: bool
    volume_divergence: bool
    candle_pattern: str

class EnhancedRealTimeMonitor:
    """å¢å¼ºç‰ˆå®æ—¶ç›‘æ§ç±»"""
    
    def __init__(self, webhook_url: str, min_volume_24h: float = None, api_key: str = None, api_secret: str = None):
        self.webhook_url = webhook_url
        self.min_volume_24h = min_volume_24h or MONITORING_CONFIG['min_volume_24h']
        self.kline_buffers = {}  # å­˜å‚¨æ¯ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®
        self.active_symbols = set()
        self.buffer_size = MONITORING_CONFIG['buffer_size']
        self.message_count = 0  # æ¶ˆæ¯è®¡æ•°å™¨
        self.pattern_count = 0  # å½¢æ€æ£€æµ‹è®¡æ•°å™¨
        self.signal_count = 0   # ä¿¡å·å‘é€è®¡æ•°å™¨
        
        # APIè®¤è¯é…ç½®
        self.api_key = api_key
        self.api_secret = api_secret
        self.base_url = 'https://fapi.binance.com'
        
        logger.info(f"åˆå§‹åŒ–ç›‘æ§å™¨: webhook_url={webhook_url}, min_volume_24h={self.min_volume_24h}")
        logger.info(f"APIè®¤è¯å·²é…ç½®: api_key={self.api_key[:8]}...")
        logger.info("ä½¿ç”¨å¸å®‰APIå®šæœŸè·å–æ•°æ®ï¼Œæ— éœ€WebSocketè¿æ¥")
    
    def _generate_signature(self, query_string: str) -> str:
        """ç”ŸæˆAPIç­¾å"""
        return hmac.new(
            self.api_secret.encode('utf-8'),
            query_string.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
    
    def _get_headers(self) -> dict:
        """è·å–APIè¯·æ±‚å¤´"""
        return {
            'X-MBX-APIKEY': self.api_key,
            'Content-Type': 'application/json'
        }
    
    async def _make_authenticated_request(self, endpoint: str, params: dict = None) -> dict:
        """å‘èµ·è®¤è¯APIè¯·æ±‚"""
        try:
            if params is None:
                params = {}
            
            # æ·»åŠ æ—¶é—´æˆ³
            params['timestamp'] = int(time.time() * 1000)
            
            # ç”ŸæˆæŸ¥è¯¢å­—ç¬¦ä¸²
            query_string = urlencode(params)
            
            # ç”Ÿæˆç­¾å
            signature = self._generate_signature(query_string)
            params['signature'] = signature
            
            # æ„å»ºå®Œæ•´URL
            url = f"{self.base_url}{endpoint}"
            
            # å‘èµ·è¯·æ±‚
            response = requests.get(url, params=params, headers=self._get_headers(), timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"è®¤è¯APIè¯·æ±‚å¤±è´¥: {e}")
            return None
        
    async def get_historical_klines(self, symbol: str, limit: int = 200) -> List[Dict]:
        """è·å–å†å²Kçº¿æ•°æ®"""
        try:
            url = "https://fapi.binance.com/fapi/v1/klines"
            params = {
                'symbol': symbol,
                'interval': '1h',
                'limit': limit
            }
            
            logger.debug(f"è·å– {symbol} å†å²æ•°æ®: {limit} æ ¹Kçº¿")
            
            # é…ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            proxies = None
            proxy_url = os.getenv('HTTP_PROXY') or os.getenv('HTTPS_PROXY')
            if proxy_url:
                proxies = {'http': proxy_url, 'https': proxy_url}
                logger.info(f"ä½¿ç”¨ä»£ç†: {proxy_url}")
            
            response = requests.get(url, params=params, timeout=30, proxies=proxies)
            
            if response.status_code != 200:
                logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥ {symbol}: {response.status_code} - {response.text}")
                if response.status_code == 451:
                    logger.error(f"åœ°ç†ä½ç½®é™åˆ¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä½¿ç”¨VPN")
                return []
            
            data = response.json()
            klines = []
            
            for kline in data:
                klines.append({
                    'timestamp': pd.to_datetime(int(kline[0]), unit='ms'),
                    'open': float(kline[1]),
                    'high': float(kline[2]),
                    'low': float(kline[3]),
                    'close': float(kline[4]),
                    'volume': float(kline[5])
                })
            
            logger.info(f"âœ… {symbol} å†å²æ•°æ®åŠ è½½å®Œæˆ: {len(klines)} æ ¹Kçº¿")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            await asyncio.sleep(0.2)  # 200mså»¶è¿Ÿ
            
            return klines
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥ {symbol}: {e}")
            return []
    
    def _generate_mock_klines(self, symbol: str, limit: int = 200) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹ŸKçº¿æ•°æ®ç”¨äºæ¼”ç¤º"""
        try:
            import random
            from datetime import datetime, timedelta
            
            logger.info(f"ç”Ÿæˆ {symbol} çš„ {limit} æ ¹æ¨¡æ‹ŸKçº¿æ•°æ®")
            
            # åŸºç¡€ä»·æ ¼è®¾å®š
            base_prices = {
                'BTCUSDT': 45000, 'ETHUSDT': 2800, 'BNBUSDT': 320,
                'ADAUSDT': 0.45, 'SOLUSDT': 95, 'XRPUSDT': 0.52,
                'DOGEUSDT': 0.08, 'DOTUSDT': 6.5, 'AVAXUSDT': 28,
                'MATICUSDT': 0.85, 'LINKUSDT': 14, 'LTCUSDT': 75
            }
            
            base_price = base_prices.get(symbol, 100.0)
            current_price = base_price
            
            klines = []
            current_time = datetime.now() - timedelta(hours=limit)
            
            for i in range(limit):
                # ç”Ÿæˆéšæœºä»·æ ¼å˜åŠ¨ï¼ˆ-2% åˆ° +2%ï¼‰
                price_change = random.uniform(-0.02, 0.02)
                new_price = current_price * (1 + price_change)
                
                # ç”ŸæˆOHLCæ•°æ®
                open_price = current_price
                close_price = new_price
                high_price = max(open_price, close_price) * random.uniform(1.0, 1.015)
                low_price = min(open_price, close_price) * random.uniform(0.985, 1.0)
                
                # ç”Ÿæˆæˆäº¤é‡
                volume = random.uniform(1000, 10000)
                
                klines.append({
                    'timestamp': current_time + timedelta(hours=i),
                    'open': round(open_price, 4),
                    'high': round(high_price, 4),
                    'low': round(low_price, 4),
                    'close': round(close_price, 4),
                    'volume': round(volume, 2)
                })
                
                current_price = new_price
            
            logger.info(f"âœ… {symbol} æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆ: {len(klines)} æ ¹Kçº¿")
            return klines
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¤±è´¥ {symbol}: {e}")
            return []
    
    async def get_active_symbols(self) -> List[str]:
        """ç›´æ¥ä½¿ç”¨å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨ä¸­çš„100ä¸ªä»£å¸"""
        try:
            logger.info("ç›´æ¥ä½¿ç”¨å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨")
            try:
                from hf_config import get_effective_symbols
                backup_symbols = get_effective_symbols()[:100]
                logger.info(f"ä½¿ç”¨å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨: {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
                return backup_symbols
            except ImportError:
                # å¦‚æœæ— æ³•å¯¼å…¥hf_configï¼Œä½¿ç”¨é»˜è®¤çš„å¤‡ç”¨åˆ—è¡¨
                backup_symbols = [
                    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'DOTUSDT',
                    'AVAXUSDT', 'MATICUSDT', 'LINKUSDT', 'LTCUSDT', 'UNIUSDT', 'ATOMUSDT', 'FILUSDT', 'TRXUSDT',
                    'ETCUSDT', 'XLMUSDT', 'VETUSDT', 'ICPUSDT', 'FTMUSDT', 'HBARUSDT', 'ALGOUSDT', 'AXSUSDT',
                    'SANDUSDT', 'MANAUSDT', 'ENJUSDT', 'CHZUSDT', 'GALAUSDT', 'FLOWUSDT', 'NEARUSDT', 'KLAYUSDT',
                    'ARUSDT', 'LRCUSDT', 'IMXUSDT', 'BATUSDT', 'IOTAUSDT', 'ZILUSDT', 'OMGUSDT', 'CRVUSDT',
                    'COMPUSDT', 'MKRUSDT', 'SNXUSDT', 'AAVEUSDT', 'YFIUSDT', 'SUSHIUSDT', '1INCHUSDT', 'ALPHAUSDT',
                    'ZENUSDT', 'SKLUSDT', 'GRTUSDT', 'BANDUSDT', 'ANKRUSDT', 'INJUSDT', 'OCEANUSDT', 'NMRUSDT',
                    'CTSIUSDT', 'STORJUSDT', 'KAVAUSDT', 'RLCUSDT', 'CTXCUSDT', 'BCHUSDT', 'LTOUSDT', 'RVNUSDT',
                    'ZECUSDT', 'XMRUSDT', 'EOSUSDT', 'QTUMUSDT', 'ZRXUSDT', 'BATUSDT', 'IOSTUSDT', 'CELRUSDT',
                    'THETAUSDT', 'TFUELUSDT', 'ONEUSDT', 'FTMUSDT', 'DUSKUSDT', 'ANKRUSDT', 'WINUSDT', 'COSUSDT',
                    'COCOSUSDT', 'MTLUSDT', 'TOMOUSDT', 'PERLUSDT', 'DENTUSDT', 'MFTUSDT', 'KEYUSDT', 'STORMXUSDT',
                    'DOCKUSDT', 'WANUSDT', 'FUNUSDT', 'CVCUSDT', 'BTTUSDT', 'WINUSDT', 'MARLINUSDT', 'UNFIUSDT',
                    'ROSEUSDT', 'AVAUSDT', 'XVSUSDT', 'UTKUSDT', 'SXPUSDT', 'TVKUSDT', 'HNTUSDT', 'DYDXUSDT'
                ]
                logger.info(f"ä½¿ç”¨é»˜è®¤å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨: {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
                return backup_symbols
            
        except Exception as e:
            logger.error(f"è·å–å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨å¤±è´¥: {e}")
            # æœ€å°å¤‡ç”¨åˆ—è¡¨
            backup_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'SOLUSDT']
            logger.info(f"ä½¿ç”¨æœ€å°å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨: {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
            return backup_symbols
    
    def calculate_basic_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å½¢æ€è¯†åˆ«å¿…éœ€çš„åŸºç¡€æŒ‡æ ‡ï¼ˆä»…ATRï¼‰"""
        if len(df) < 50:
            logger.debug(f"æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—åŸºç¡€æŒ‡æ ‡: {len(df)} < 50")
            return df
            
        try:
            logger.debug(f"è®¡ç®—åŸºç¡€æŒ‡æ ‡ï¼ˆATRï¼‰ï¼Œæ•°æ®é•¿åº¦: {len(df)}")
            
            # ATR - å½¢æ€è¯†åˆ«å¿…éœ€
            df['atr'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)
            
            logger.debug("åŸºç¡€æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            return df
            
        except Exception as e:
            logger.error(f"è®¡ç®—åŸºç¡€æŒ‡æ ‡å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return df
    
    def calculate_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ï¼ˆç”¨äºä¿¡å·åˆ†æï¼‰"""
        if len(df) < 50:
            logger.debug(f"æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡: {len(df)} < 50")
            return df
            
        try:
            logger.debug(f"è®¡ç®—å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ï¼Œæ•°æ®é•¿åº¦: {len(df)}")
            
            # å…ˆè®¡ç®—åŸºç¡€æŒ‡æ ‡
            df = self.calculate_basic_indicators(df)
            
            # EMAå‡çº¿
            df['ema21'] = talib.EMA(df['close'], timeperiod=21)
            df['ema55'] = talib.EMA(df['close'], timeperiod=55)
            df['ema144'] = talib.EMA(df['close'], timeperiod=144)
            
            # MACD
            df['macd'], df['macd_signal'], df['macd_hist'] = talib.MACD(
                df['close'], fastperiod=12, slowperiod=26, signalperiod=9
            )
            
            # RSI
            df['rsi'] = talib.RSI(df['close'], timeperiod=14)
            
            # æˆäº¤é‡å‡çº¿
            df['volume_ma'] = talib.SMA(df['volume'], timeperiod=20)
            
            logger.debug("å®Œæ•´æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
            return df
            
        except Exception as e:
            logger.error(f"è®¡ç®—æŒ‡æ ‡å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return df
    
    def find_enhanced_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """åŸºäºATRçš„å½¢æ€è¯†åˆ« - ç¬¦åˆå›æµ‹æ¡ä»¶"""
        patterns = []
        
        if len(df) < 100:
            print(f"â³ [å½¢æ€æ£€æµ‹] æ•°æ®ä¸è¶³100æ ¹Kçº¿ ({len(df)}/100)ï¼Œè·³è¿‡å½¢æ€è¯†åˆ«")
            logger.debug(f"æ•°æ®ä¸è¶³è¿›è¡Œå½¢æ€è¯†åˆ«: {len(df)} < 100")
            return patterns
            
        try:
            print(f"ğŸ” [å½¢æ€æ£€æµ‹] å¼€å§‹å½¢æ€è¯†åˆ«ï¼Œæ•°æ®é‡: {len(df)} æ ¹Kçº¿")
            logger.debug(f"å¼€å§‹ATRå½¢æ€è¯†åˆ«ï¼Œæ•°æ®é•¿åº¦: {len(df)}")
            
            # ç¡®ä¿ATRå·²è®¡ç®—
            if 'atr' not in df.columns or df['atr'].isna().all():
                print(f"âŒ [ATRæ£€æŸ¥] ATRæŒ‡æ ‡æœªè®¡ç®—æˆ–å…¨ä¸ºNaNï¼Œè·³è¿‡å½¢æ€è¯†åˆ«")
                logger.warning("ATRæŒ‡æ ‡æœªè®¡ç®—æˆ–å…¨ä¸ºNaN")
                return patterns
            
            # åŒé¡¶/åŒåº•æ£€æµ‹ - åŸºäº1hç²’åº¦ï¼Œæ»‘åŠ¨çª—å£10
            print(f"ğŸ” [åŒé¡¶åŒåº•] å¼€å§‹æ£€æµ‹åŒé¡¶åŒåº•å½¢æ€...")
            double_patterns = self._detect_double_patterns(df)
            if double_patterns:
                print(f"âœ… [åŒé¡¶åŒåº•] å‘ç° {len(double_patterns)} ä¸ªåŒé¡¶åŒåº•å½¢æ€: {[p['type'] for p in double_patterns]}")
            else:
                print(f"âŒ [åŒé¡¶åŒåº•] æœªå‘ç°åŒé¡¶åŒåº•å½¢æ€")
            patterns.extend(double_patterns)
            
            # å¤´è‚©é¡¶/å¤´è‚©åº•æ£€æµ‹ - åŸºäº1hç²’åº¦ï¼Œæ»‘åŠ¨çª—å£7ï¼ŒKçº¿è·¨åº¦100æ ¹
            print(f"ğŸ” [å¤´è‚©å½¢æ€] å¼€å§‹æ£€æµ‹å¤´è‚©å½¢æ€...")
            head_shoulder_patterns = self._detect_head_shoulder_patterns(df)
            if head_shoulder_patterns:
                print(f"âœ… [å¤´è‚©å½¢æ€] å‘ç° {len(head_shoulder_patterns)} ä¸ªå¤´è‚©å½¢æ€: {[p['type'] for p in head_shoulder_patterns]}")
            else:
                print(f"âŒ [å¤´è‚©å½¢æ€] æœªå‘ç°å¤´è‚©å½¢æ€")
            patterns.extend(head_shoulder_patterns)
            
            total_patterns = len(patterns)
            if total_patterns > 0:
                print(f"ğŸ¯ [å½¢æ€æ±‡æ€»] æ€»å…±å‘ç° {total_patterns} ä¸ªå½¢æ€")
            else:
                print(f"ğŸ” [å½¢æ€æ±‡æ€»] æœªå‘ç°ä»»ä½•å½¢æ€")
            
            logger.info(f"ATRå½¢æ€è¯†åˆ«å®Œæˆï¼Œæ‰¾åˆ° {len(patterns)} ä¸ªå½¢æ€")
            return patterns
            
        except Exception as e:
            print(f"âŒ [å½¢æ€è¯†åˆ«] å½¢æ€è¯†åˆ«å¤±è´¥: {e}")
            logger.error(f"å½¢æ€è¯†åˆ«å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []
    
    def _detect_double_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹åŒé¡¶/åŒåº•å½¢æ€ - å®Œå…¨æŒ‰ç…§å›æµ‹è„šæœ¬é€»è¾‘"""
        patterns = []
        
        if len(df) < 50:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
            return patterns
            
        try:
            from scipy.signal import argrelextrema
            
            # è®¡ç®—ATRç›¸å¯¹äºä»·æ ¼çš„æ³¢åŠ¨ç‡
            atr_volatility = (df['atr'] / df['close']).mean()
            
            # å¯»æ‰¾å±€éƒ¨é«˜ç‚¹å’Œä½ç‚¹
            high_idx = argrelextrema(df['high'].values, np.greater, order=10)[0]
            low_idx = argrelextrema(df['low'].values, np.less, order=10)[0]
            
            # è¯†åˆ«åŒé¡¶å½¢æ€
            for i in range(1, len(high_idx)-1):
                idx1 = int(high_idx[i-1])  # ç¬¬ä¸€ä¸ªé¡¶
                idx2 = int(high_idx[i])    # ç¬¬äºŒä¸ªé¡¶
                
                # æ£€æŸ¥ä¸¤ä¸ªé¡¶ä¹‹é—´çš„æ—¶é—´è·¨åº¦
                if abs(idx2 - idx1) > 100:  # æ”¾å®½æ—¶é—´è·¨åº¦é™åˆ¶
                    continue
                    
                # æ£€æŸ¥ä¸¤ä¸ªé¡¶çš„ä»·æ ¼å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                avg_price = (df['high'].iloc[idx1] + df['high'].iloc[idx2]) / 2
                price_diff = abs(df['high'].iloc[idx1] - df['high'].iloc[idx2])
                price_diff_ratio = price_diff / avg_price
                if price_diff_ratio > 1.0 * atr_volatility:  # ä»·æ ¼å·®å¼‚é˜ˆå€¼
                    continue
                    
                # æ‰¾åˆ°ä¸¤ä¸ªé¡¶ä¹‹é—´çš„æœ€ä½ç‚¹
                start, end = min(idx1, idx2), max(idx1, idx2)
                if start >= end:  # è¾¹ç•Œæ£€æŸ¥
                    continue
                trough_label = df['low'].iloc[start:end+1].idxmin()
                trough_idx = df.index.get_loc(trough_label)  # è½¬æ¢ä¸ºä½ç½®ç´¢å¼•
                trough_price = df['low'].loc[trough_label]
                
                # æ£€æŸ¥é¡¶ä¸æœ€ä½ç‚¹çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                height_diff1 = abs(df['high'].iloc[idx1] - trough_price)
                height_diff2 = abs(df['high'].iloc[idx2] - trough_price)
                
                price1 = df['high'].iloc[idx1]
                price2 = df['high'].iloc[idx2]
                height_ratio1 = height_diff1 / price1
                height_ratio2 = height_diff2 / price2
                if (height_ratio1 < 2.0 * atr_volatility or 
                    height_ratio2 < 2.0 * atr_volatility):  # é«˜åº¦å·®è¦æ±‚
                    continue
                    
                # è®°å½•åŒé¡¶å½¢æ€
                patterns.append({
                    'type': 'double_top',
                    'idx1': idx1,
                    'idx2': idx2,
                    'trough_idx': trough_idx,
                    'timestamp': df.index[idx2],
                    'price': df['close'].iloc[idx2],
                    'pattern_idx': idx2  # ä½¿ç”¨ç¬¬äºŒä¸ªé¡¶ä½œä¸ºå½¢æ€ç¡®è®¤ç‚¹
                })
                logger.info(f"å‘ç°åŒé¡¶å½¢æ€: ä»·æ ¼å·®å¼‚æ¯”ç‡={price_diff_ratio:.3f}, é«˜åº¦æ¯”ç‡1={height_ratio1:.3f}, é«˜åº¦æ¯”ç‡2={height_ratio2:.3f}")
            
            # è¯†åˆ«åŒåº•å½¢æ€
            for i in range(1, len(low_idx)-1):
                idx1 = int(low_idx[i-1])  # ç¬¬ä¸€ä¸ªåº•
                idx2 = int(low_idx[i])    # ç¬¬äºŒä¸ªåº•
                
                # æ£€æŸ¥ä¸¤ä¸ªåº•ä¹‹é—´çš„æ—¶é—´è·¨åº¦
                if abs(idx2 - idx1) > 100:  # æ”¾å®½æ—¶é—´è·¨åº¦é™åˆ¶
                    continue
                    
                # æ£€æŸ¥ä¸¤ä¸ªåº•çš„ä»·æ ¼å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                avg_price = (df['low'].iloc[idx1] + df['low'].iloc[idx2]) / 2
                price_diff = abs(df['low'].iloc[idx1] - df['low'].iloc[idx2])
                price_diff_ratio = price_diff / avg_price
                if price_diff_ratio > 1.0 * atr_volatility:  # ä»·æ ¼å·®å¼‚é˜ˆå€¼
                    continue
                    
                # æ‰¾åˆ°ä¸¤ä¸ªåº•ä¹‹é—´çš„æœ€é«˜ç‚¹
                start, end = min(idx1, idx2), max(idx1, idx2)
                if start >= end:  # è¾¹ç•Œæ£€æŸ¥
                    continue
                peak_label = df['high'].iloc[start:end+1].idxmax()
                peak_idx = df.index.get_loc(peak_label)  # è½¬æ¢ä¸ºä½ç½®ç´¢å¼•
                peak_price = df['high'].loc[peak_label]
                
                # æ£€æŸ¥åº•ä¸æœ€é«˜ç‚¹çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                height_diff1 = abs(peak_price - df['low'].iloc[idx1])
                height_diff2 = abs(peak_price - df['low'].iloc[idx2])
                
                price1 = df['low'].iloc[idx1]
                price2 = df['low'].iloc[idx2]
                height_ratio1 = height_diff1 / price1
                height_ratio2 = height_diff2 / price2
                if (height_ratio1 < 2.0 * atr_volatility or 
                    height_ratio2 < 2.0 * atr_volatility):  # é«˜åº¦å·®è¦æ±‚
                    continue
                    
                # è®°å½•åŒåº•å½¢æ€
                patterns.append({
                    'type': 'double_bottom',
                    'idx1': idx1,
                    'idx2': idx2,
                    'peak_idx': peak_idx,
                    'timestamp': df.index[idx2],
                    'price': df['close'].iloc[idx2],
                    'pattern_idx': idx2  # ä½¿ç”¨ç¬¬äºŒä¸ªåº•ä½œä¸ºå½¢æ€ç¡®è®¤ç‚¹
                })
                logger.info(f"å‘ç°åŒåº•å½¢æ€: ä»·æ ¼å·®å¼‚æ¯”ç‡={price_diff_ratio:.3f}, é«˜åº¦æ¯”ç‡1={height_ratio1:.3f}, é«˜åº¦æ¯”ç‡2={height_ratio2:.3f}")
            
            return patterns
            
        except Exception as e:
            logger.error(f"åŒé¡¶/åŒåº•æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_head_shoulder_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹å¤´è‚©é¡¶/å¤´è‚©åº•å½¢æ€ - å®Œå…¨æŒ‰ç…§å›æµ‹è„šæœ¬é€»è¾‘"""
        patterns = []
        
        if len(df) < 100:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
            return patterns
            
        try:
            from scipy.signal import argrelextrema
            
            # è®¡ç®—ATRç›¸å¯¹äºä»·æ ¼çš„æ³¢åŠ¨ç‡
            atr_volatility = (df['atr'] / df['close']).mean()
            
            # å¯»æ‰¾å±€éƒ¨é«˜ç‚¹å’Œä½ç‚¹
            high_idx = argrelextrema(df['high'].values, np.greater, order=7)[0]
            low_idx = argrelextrema(df['low'].values, np.less, order=7)[0]
            
            # è¯†åˆ«å¤´è‚©é¡¶å½¢æ€
            for i in range(2, len(high_idx)-2):
                left_shoulder_idx = int(high_idx[i-2])  # å·¦è‚©
                head_idx = int(high_idx[i-1])           # å¤´
                right_shoulder_idx = int(high_idx[i])   # å³è‚©
                
                # æ£€æŸ¥æ—¶é—´è·¨åº¦ - ä¿®æ”¹ä¸º100ä¸ªå‘¨æœŸå†…
                if (abs(head_idx - left_shoulder_idx) > 100 or 
                    abs(right_shoulder_idx - head_idx) > 100):  # 100ä¸ªå‘¨æœŸå†…çš„æ—¶é—´è·¨åº¦
                    continue
                    
                # è·å–ä»·æ ¼
                head_price = df['high'].iloc[head_idx]
                left_shoulder_price = df['high'].iloc[left_shoulder_idx]
                right_shoulder_price = df['high'].iloc[right_shoulder_idx]
                
                # æ¡ä»¶1ï¼šå¤´éƒ¨å¿…é¡»æ˜¯æœ€é«˜ç‚¹ï¼ˆè¿™ä¸ªæ¡ä»¶å¿…é¡»æ»¡è¶³ï¼‰
                if head_price <= left_shoulder_price or head_price <= right_shoulder_price:
                    continue
                    
                # æ¡ä»¶2ï¼šå¤´éƒ¨å’Œä¸¤è‚©å¯ä»¥å‡ ä¹æŒå¹³ï¼Œä½†ä¸èƒ½ç›¸å·®å¤ªå¤§
                # å¤´å’Œè‚©çš„æœ€å¤§å·®è·ä¸èƒ½å¤§äº2*atræ³¢åŠ¨ç‡
                head_shoulder_diff1 = abs(head_price - left_shoulder_price)
                head_shoulder_diff2 = abs(head_price - right_shoulder_price)
                
                head_shoulder_ratio1 = head_shoulder_diff1 / head_price
                head_shoulder_ratio2 = head_shoulder_diff2 / head_price
                if (head_shoulder_ratio1 > 2.0 * atr_volatility or 
                    head_shoulder_ratio2 > 2.0 * atr_volatility):  # å¤´è‚©é«˜åº¦å·®ä¸èƒ½å¤ªå¤§
                    continue
                    
                # æ£€æŸ¥ä¸¤è‚©çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                avg_shoulder_price = (left_shoulder_price + right_shoulder_price) / 2
                shoulder_diff = abs(left_shoulder_price - right_shoulder_price)
                shoulder_diff_ratio = shoulder_diff / avg_shoulder_price
                if shoulder_diff_ratio > 1.0 * atr_volatility:  # ä¸¤è‚©å¯¹ç§°æ€§è¦æ±‚
                    continue
                    
                # æ‰¾åˆ°å¤´ä¸ä¸¤è‚©ä¹‹é—´çš„æœ€ä½ç‚¹
                start, end = min(left_shoulder_idx, right_shoulder_idx), max(left_shoulder_idx, right_shoulder_idx)
                if start >= end:  # è¾¹ç•Œæ£€æŸ¥
                    continue
                trough_label = df['low'].iloc[start:end+1].idxmin()
                trough_idx = df.index.get_loc(trough_label)  # è½¬æ¢ä¸ºä½ç½®ç´¢å¼•
                trough_price = df['low'].loc[trough_label]
                
                # æ£€æŸ¥å¤´ä¸æœ€ä½ç‚¹çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                height_diff = abs(head_price - trough_price)
                height_ratio = height_diff / head_price
                if height_ratio < 1.5 * atr_volatility:  # é™ä½æ•´ä½“é«˜åº¦è¦æ±‚
                    continue
                    
                # è®°å½•å¤´è‚©é¡¶å½¢æ€
                patterns.append({
                    'type': 'head_shoulder_top',
                    'left_shoulder_idx': left_shoulder_idx,
                    'head_idx': head_idx,
                    'right_shoulder_idx': right_shoulder_idx,
                    'trough_idx': trough_idx,
                    'timestamp': df.index[right_shoulder_idx],
                    'price': df['close'].iloc[right_shoulder_idx],
                    'pattern_idx': right_shoulder_idx  # ä½¿ç”¨å³è‚©ä½œä¸ºå½¢æ€ç¡®è®¤ç‚¹
                })
                logger.info(f"å‘ç°å¤´è‚©é¡¶å½¢æ€: å¤´è‚©æ¯”ç‡1={head_shoulder_ratio1:.3f}, å¤´è‚©æ¯”ç‡2={head_shoulder_ratio2:.3f}, è‚©å·®æ¯”ç‡={shoulder_diff_ratio:.3f}")
            
            # è¯†åˆ«å¤´è‚©åº•å½¢æ€
            for i in range(2, len(low_idx)-2):
                left_shoulder_idx = int(low_idx[i-2])  # å·¦è‚©
                head_idx = int(low_idx[i-1])           # å¤´
                right_shoulder_idx = int(low_idx[i])   # å³è‚©
                
                # æ£€æŸ¥æ—¶é—´è·¨åº¦ - ä¿®æ”¹ä¸º100ä¸ªå‘¨æœŸå†…
                if (abs(head_idx - left_shoulder_idx) > 100 or 
                    abs(right_shoulder_idx - head_idx) > 100):  # 100ä¸ªå‘¨æœŸå†…çš„æ—¶é—´è·¨åº¦
                    continue
                    
                # è·å–ä»·æ ¼
                head_price = df['low'].iloc[head_idx]
                left_shoulder_price = df['low'].iloc[left_shoulder_idx]
                right_shoulder_price = df['low'].iloc[right_shoulder_idx]
                
                # æ¡ä»¶1ï¼šå¤´éƒ¨å¿…é¡»æ˜¯æœ€ä½ç‚¹ï¼ˆè¿™ä¸ªæ¡ä»¶å¿…é¡»æ»¡è¶³ï¼‰
                if head_price >= left_shoulder_price or head_price >= right_shoulder_price:
                    continue
                    
                # æ¡ä»¶2ï¼šå¤´éƒ¨å’Œä¸¤è‚©å¯ä»¥å‡ ä¹æŒå¹³ï¼Œä½†ä¸èƒ½ç›¸å·®å¤ªå¤§
                # å¤´å’Œè‚©çš„æœ€å¤§å·®è·ä¸èƒ½å¤§äº2*atræ³¢åŠ¨ç‡
                head_shoulder_diff1 = abs(head_price - left_shoulder_price)
                head_shoulder_diff2 = abs(head_price - right_shoulder_price)
                
                # å¯¹äºå¤´è‚©åº•ï¼Œä½¿ç”¨å¤´éƒ¨ä»·æ ¼ä½œä¸ºå‚è€ƒ
                head_shoulder_ratio1 = head_shoulder_diff1 / abs(head_price)
                head_shoulder_ratio2 = head_shoulder_diff2 / abs(head_price)
                if (head_shoulder_ratio1 > 2.0 * atr_volatility or 
                    head_shoulder_ratio2 > 2.0 * atr_volatility):  # å¤´è‚©é«˜åº¦å·®ä¸èƒ½å¤ªå¤§
                    continue
                    
                # æ£€æŸ¥ä¸¤è‚©çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                avg_shoulder_price = (left_shoulder_price + right_shoulder_price) / 2
                shoulder_diff = abs(left_shoulder_price - right_shoulder_price)
                shoulder_diff_ratio = shoulder_diff / avg_shoulder_price
                if shoulder_diff_ratio > 1.0 * atr_volatility:  # ä¸¤è‚©å¯¹ç§°æ€§è¦æ±‚
                    continue
                    
                # æ‰¾åˆ°å¤´ä¸ä¸¤è‚©ä¹‹é—´çš„æœ€é«˜ç‚¹
                start, end = min(left_shoulder_idx, right_shoulder_idx), max(left_shoulder_idx, right_shoulder_idx)
                if start >= end:  # è¾¹ç•Œæ£€æŸ¥
                    continue
                peak_label = df['high'].iloc[start:end+1].idxmax()
                peak_idx = df.index.get_loc(peak_label)  # è½¬æ¢ä¸ºä½ç½®ç´¢å¼•
                peak_price = df['high'].loc[peak_label]
                
                # æ£€æŸ¥å¤´ä¸æœ€é«˜ç‚¹çš„é«˜åº¦å·®ï¼ˆä½¿ç”¨ç›¸å¯¹æ³¢åŠ¨ç‡ï¼‰
                height_diff = abs(peak_price - head_price)
                height_ratio = height_diff / abs(head_price)
                if height_ratio < 1.5 * atr_volatility:  # é™ä½æ•´ä½“é«˜åº¦è¦æ±‚
                    continue
                    
                # è®°å½•å¤´è‚©åº•å½¢æ€
                patterns.append({
                    'type': 'head_shoulder_bottom',
                    'left_shoulder_idx': left_shoulder_idx,
                    'head_idx': head_idx,
                    'right_shoulder_idx': right_shoulder_idx,
                    'peak_idx': peak_idx,
                    'timestamp': df.index[right_shoulder_idx],
                    'price': df['close'].iloc[right_shoulder_idx],
                    'pattern_idx': right_shoulder_idx  # ä½¿ç”¨å³è‚©ä½œä¸ºå½¢æ€ç¡®è®¤ç‚¹
                })
                logger.info(f"å‘ç°å¤´è‚©åº•å½¢æ€: å¤´è‚©æ¯”ç‡1={head_shoulder_ratio1:.3f}, å¤´è‚©æ¯”ç‡2={head_shoulder_ratio2:.3f}, è‚©å·®æ¯”ç‡={shoulder_diff_ratio:.3f}")
            
            return patterns
            
        except Exception as e:
            logger.error(f"å¤´è‚©å½¢æ€æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def check_trend_status(self, df: pd.DataFrame, idx: int) -> str:
        """æ£€æŸ¥è¶‹åŠ¿çŠ¶æ€ - å®Œå…¨æŒ‰ç…§å›æµ‹è„šæœ¬é€»è¾‘"""
        try:
            if idx < 50 or 'ema21' not in df.columns or 'ema55' not in df.columns:
                logger.debug(f"è¶‹åŠ¿æ£€æŸ¥: æ•°æ®ä¸è¶³ idx={idx}")
                return 'insufficient_data'
                
            ema21 = df.iloc[idx]['ema21']
            ema55 = df.iloc[idx]['ema55']
            
            if pd.isna(ema21) or pd.isna(ema55):
                return 'insufficient_data'
            
            logger.debug(f"EMAå€¼: EMA21={ema21:.4f}, EMA55={ema55:.4f}")
            
            # åŸºäºEMAçš„è¶‹åŠ¿åˆ¤æ–­ - ä¸å›æµ‹è„šæœ¬ä¸€è‡´
            if ema21 > ema55:
                return 'uptrend'
            elif ema21 < ema55:
                return 'downtrend'
            else:
                return 'sideways'
                
        except Exception as e:
            logger.error(f"è¶‹åŠ¿æ£€æŸ¥å¤±è´¥: {e}")
            return 'error'
    
    def check_macd_divergence(self, df: pd.DataFrame, pattern_type: str, idx1: int, idx2: int) -> bool:
        """æ£€æŸ¥MACDèƒŒç¦»"""
        try:
            if not DIVERGENCE_CONFIG['macd']['enabled']:
                return False
                
            if idx2 >= len(df) or idx1 < 0:
                return False
                
            price1, price2 = df.iloc[idx1]['close'], df.iloc[idx2]['close']
            macd1, macd2 = df.iloc[idx1]['macd'], df.iloc[idx2]['macd']
            
            if pd.isna(macd1) or pd.isna(macd2):
                return False
            
            # è®¡ç®—èƒŒç¦»å¼ºåº¦
            price_change = abs(price2 - price1) / price1
            macd_change = abs(macd2 - macd1) / abs(macd1) if macd1 != 0 else 0
            
            logger.debug(f"MACDèƒŒç¦»æ£€æŸ¥: price_change={price_change:.3%}, macd_change={macd_change:.3%}")
            
            # é™ä½æœ€å°å¼ºåº¦è¦æ±‚
            min_strength = DIVERGENCE_CONFIG['macd']['min_strength'] * 0.5  # é™ä½50%
            if price_change < min_strength:
                return False
                
            if 'top' in pattern_type.lower():
                divergence = price2 > price1 and macd2 < macd1
            else:
                divergence = price2 < price1 and macd2 > macd1
                
            if divergence:
                logger.info(f"æ£€æµ‹åˆ°MACDèƒŒç¦»: {pattern_type}")
                
            return divergence
                
        except Exception as e:
            logger.error(f"MACDèƒŒç¦»æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def check_rsi_divergence(self, df: pd.DataFrame, pattern_type: str, idx1: int, idx2: int) -> bool:
        """æ£€æŸ¥RSIèƒŒç¦»"""
        try:
            if not DIVERGENCE_CONFIG['rsi']['enabled']:
                return False
                
            if idx2 >= len(df) or idx1 < 0:
                return False
                
            price1, price2 = df.iloc[idx1]['close'], df.iloc[idx2]['close']
            rsi1, rsi2 = df.iloc[idx1]['rsi'], df.iloc[idx2]['rsi']
            
            if pd.isna(rsi1) or pd.isna(rsi2):
                return False
            
            # è®¡ç®—RSIèƒŒç¦»å¼ºåº¦
            rsi_diff = abs(rsi2 - rsi1)
            
            logger.debug(f"RSIèƒŒç¦»æ£€æŸ¥: rsi1={rsi1:.2f}, rsi2={rsi2:.2f}, diff={rsi_diff:.2f}")
            
            # é™ä½æœ€å°å¼ºåº¦è¦æ±‚
            min_strength = DIVERGENCE_CONFIG['rsi']['min_strength'] * 0.5  # é™ä½50%
            if rsi_diff < min_strength:
                return False
                
            if 'top' in pattern_type.lower():
                divergence = price2 > price1 and rsi2 < rsi1
            else:
                divergence = price2 < price1 and rsi2 > rsi1
                
            if divergence:
                logger.info(f"æ£€æµ‹åˆ°RSIèƒŒç¦»: {pattern_type}")
                
            return divergence
                
        except Exception as e:
            logger.error(f"RSIèƒŒç¦»æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def check_volume_divergence(self, df: pd.DataFrame, pattern_type: str, idx1: int, idx2: int) -> bool:
        """æ£€æŸ¥æˆäº¤é‡èƒŒç¦»"""
        try:
            if not DIVERGENCE_CONFIG['volume']['enabled']:
                return False
                
            if idx2 >= len(df) or idx1 < 0:
                return False
                
            price1, price2 = df.iloc[idx1]['close'], df.iloc[idx2]['close']
            vol1, vol2 = df.iloc[idx1]['volume'], df.iloc[idx2]['volume']
            
            # è®¡ç®—æˆäº¤é‡å˜åŒ–å¼ºåº¦
            vol_change = abs(vol2 - vol1) / vol1 if vol1 > 0 else 0
            
            logger.debug(f"æˆäº¤é‡èƒŒç¦»æ£€æŸ¥: vol1={vol1:.0f}, vol2={vol2:.0f}, change={vol_change:.3%}")
            
            # é™ä½æœ€å°å¼ºåº¦è¦æ±‚
            min_strength = DIVERGENCE_CONFIG['volume']['min_strength'] * 0.5  # é™ä½50%
            if vol_change < min_strength:
                return False
            
            if 'top' in pattern_type.lower():
                divergence = price2 > price1 and vol2 < vol1
            else:
                divergence = price2 < price1 and vol2 > vol1
                
            if divergence:
                logger.info(f"æ£€æµ‹åˆ°æˆäº¤é‡èƒŒç¦»: {pattern_type}")
                
            return divergence
                
        except Exception as e:
            logger.error(f"æˆäº¤é‡èƒŒç¦»æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def check_candle_pattern(self, df: pd.DataFrame, idx: int) -> str:
        """æ£€æŸ¥èœ¡çƒ›å½¢æ€ - å®Œå…¨æŒ‰ç…§å›æµ‹è„šæœ¬é€»è¾‘"""
        try:
            if idx < 1 or idx >= len(df):
                return 'none'
                
            current = df.iloc[idx]
            previous = df.iloc[idx-1]
            
            open_price, high, low, close = current['open'], current['high'], current['low'], current['close']
            prev_open, prev_high, prev_low, prev_close = previous['open'], previous['high'], previous['low'], previous['close']
            
            # è®¡ç®—å®ä½“å’Œå½±çº¿
            body_size = abs(close - open_price)
            upper_shadow = high - max(open_price, close)
            lower_shadow = min(open_price, close) - low
            total_range = high - low
            
            prev_body = abs(prev_close - prev_open)
            
            logger.debug(f"èœ¡çƒ›å½¢æ€æ£€æŸ¥: body={body_size:.4f}, upper_shadow={upper_shadow:.4f}, lower_shadow={lower_shadow:.4f}, total_range={total_range:.4f}")
            
            if total_range == 0:
                return 'none'
            
            # åå­—æ˜Ÿå½¢æ€ï¼šå®ä½“å°äºæ€»èŒƒå›´çš„10%
            if body_size / total_range < 0.1:
                logger.info(f"æ£€æµ‹åˆ°åå­—æ˜Ÿå½¢æ€: å®ä½“æ¯”ç‡={body_size / total_range:.3f}")
                return 'doji'
            
            # é”¤å­çº¿ï¼šä¸‹å½±çº¿è‡³å°‘æ˜¯å®ä½“çš„2å€ï¼Œä¸Šå½±çº¿å°äºå®ä½“çš„ä¸€åŠ
            if (lower_shadow >= 2 * body_size and 
                upper_shadow <= body_size * 0.5 and
                body_size / total_range >= 0.1):  # å®ä½“ä¸èƒ½å¤ªå°
                
                pattern_type = 'hammer' if close > open_price else 'hanging_man'
                logger.info(f"æ£€æµ‹åˆ°{pattern_type}å½¢æ€: ä¸‹å½±çº¿æ¯”ç‡={lower_shadow / total_range:.3f}")
                return pattern_type
                
            # å°„å‡»ä¹‹æ˜Ÿï¼šä¸Šå½±çº¿è‡³å°‘æ˜¯å®ä½“çš„2å€ï¼Œä¸‹å½±çº¿å°äºå®ä½“çš„ä¸€åŠ
            if (upper_shadow >= 2 * body_size and 
                lower_shadow <= body_size * 0.5 and
                body_size / total_range >= 0.1):  # å®ä½“ä¸èƒ½å¤ªå°
                
                pattern_type = 'shooting_star' if close < open_price else 'inverted_hammer'
                logger.info(f"æ£€æµ‹åˆ°{pattern_type}å½¢æ€: ä¸Šå½±çº¿æ¯”ç‡={upper_shadow / total_range:.3f}")
                return pattern_type
            
            # çœ‹æ¶¨åæ²¡ï¼šå½“å‰é˜³çº¿å®Œå…¨åæ²¡å‰ä¸€æ ¹é˜´çº¿
            if (close > open_price and prev_close < prev_open and
                open_price < prev_close and close > prev_open and
                body_size > prev_body):  # å½“å‰å®ä½“å¤§äºå‰ä¸€æ ¹å®ä½“
                
                logger.info(f"æ£€æµ‹åˆ°çœ‹æ¶¨åæ²¡å½¢æ€: åæ²¡æ¯”ç‡={body_size / prev_body:.3f}")
                return 'bullish_engulfing'
            
            # çœ‹è·Œåæ²¡ï¼šå½“å‰é˜´çº¿å®Œå…¨åæ²¡å‰ä¸€æ ¹é˜³çº¿
            if (close < open_price and prev_close > prev_open and
                open_price > prev_close and close < prev_open and
                body_size > prev_body):  # å½“å‰å®ä½“å¤§äºå‰ä¸€æ ¹å®ä½“
                
                logger.info(f"æ£€æµ‹åˆ°çœ‹è·Œåæ²¡å½¢æ€: åæ²¡æ¯”ç‡={body_size / prev_body:.3f}")
                return 'bearish_engulfing'
            
            return 'none'
            
        except Exception as e:
            logger.error(f"èœ¡çƒ›å½¢æ€æ£€æŸ¥å¤±è´¥: {e}")
            return 'error'
    
    async def send_signal_to_webhook(self, signal: SignalData):
        """å‘é€ä¿¡å·åˆ°webhookï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        # ä¿®å¤payloadç»“æ„ï¼Œä½¿å…¶ä¸SignalDataä¸€è‡´
        payload = {
            'symbol': signal.symbol,
            'timestamp': signal.timestamp.isoformat(),
            'price': signal.price,
            'pattern_type': signal.pattern_type,
            'trend_status': signal.trend_status,
            'macd_divergence': signal.macd_divergence,
            'rsi_divergence': signal.rsi_divergence,
            'volume_divergence': signal.volume_divergence,
            'candle_pattern': signal.candle_pattern
        }
        
        print(f"\nğŸ“¡ [Webhookå‘é€] {signal.symbol} å‡†å¤‡å‘é€ä¿¡å·:")
        print(f"   ğŸ¯ ç›®æ ‡URL: {self.webhook_url[:50]}...")
        print(f"   ğŸ“¦ è½½è·å¤§å°: {len(str(payload))} å­—ç¬¦")
        logger.info(f"å‡†å¤‡å‘é€ä¿¡å·: {signal.symbol} - {signal.pattern_type}")
        logger.debug(f"ä¿¡å·è¯¦æƒ…: {payload}")
        
        for attempt in range(WEBHOOK_CONFIG['retry_attempts']):
            try:
                response = requests.post(
                    self.webhook_url, 
                    json=payload, 
                    timeout=WEBHOOK_CONFIG['timeout']
                )
                
                if response.status_code == 200:
                    print(f"âœ… [å‘é€æˆåŠŸ] {signal.symbol} ä¿¡å·å‘é€æˆåŠŸ! (å°è¯• {attempt + 1}/{WEBHOOK_CONFIG['retry_attempts']})")
                    logger.info(f"âœ… ä¿¡å·å‘é€æˆåŠŸ: {signal.symbol} - {signal.pattern_type}")
                    self.signal_count += 1
                    return
                else:
                    print(f"âš ï¸ [å‘é€å¤±è´¥] {signal.symbol} HTTP {response.status_code} (å°è¯• {attempt + 1}/{WEBHOOK_CONFIG['retry_attempts']})")
                    logger.warning(f"ä¿¡å·å‘é€å¤±è´¥ (å°è¯• {attempt + 1}/{WEBHOOK_CONFIG['retry_attempts']}): {response.status_code} - {response.text}")
                    
            except Exception as e:
                print(f"âŒ [å‘é€å¼‚å¸¸] {signal.symbol} å‘é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{WEBHOOK_CONFIG['retry_attempts']}): {e}")
                logger.error(f"ä¿¡å·å‘é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{WEBHOOK_CONFIG['retry_attempts']}): {e}")
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
            if attempt < WEBHOOK_CONFIG['retry_attempts'] - 1:
                print(f"â³ [é‡è¯•ç­‰å¾…] {signal.symbol} {WEBHOOK_CONFIG['retry_delay']}ç§’åé‡è¯•...")
                await asyncio.sleep(WEBHOOK_CONFIG['retry_delay'])
        
        print(f"ğŸ’¥ [æœ€ç»ˆå¤±è´¥] {signal.symbol} æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä¿¡å·å‘é€å¤±è´¥!")
        logger.error(f"âŒ ä¿¡å·å‘é€æœ€ç»ˆå¤±è´¥: {signal.symbol} - {signal.pattern_type}")
    
    def process_kline_data(self, symbol: str, kline_data: Dict):
        """å¤„ç†Kçº¿æ•°æ® - å®šæ—¶æ¨¡å¼"""
        try:
            # æ£€æŸ¥æ•°æ®ç¼“å†²åŒºæ˜¯å¦å­˜åœ¨
            if symbol not in self.kline_buffers:
                print(f"âš ï¸ [ç¼“å­˜æ£€æŸ¥] {symbol} æ•°æ®ç¼“å†²åŒºä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ç©ºç¼“å†²åŒº")
                logger.warning(f"{symbol} æ•°æ®ç¼“å†²åŒºä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºç¼“å†²åŒº")
                self.kline_buffers[symbol] = deque(maxlen=self.buffer_size)
            
            # è·å–å½“å‰ç¼“å­˜æ•°é‡
            current_cache_count = len(self.kline_buffers[symbol])
            print(f"ğŸ“Š [ç¼“å­˜çŠ¶æ€] {symbol} å½“å‰ç¼“å­˜: {current_cache_count}/{self.buffer_size} æ ¹Kçº¿")
            
            # æ•°æ®è½¬æ¢
            print(f"ğŸ”„ [æ•°æ®è½¬æ¢] {symbol} è½¬æ¢å®šæ—¶è·å–çš„Kçº¿æ•°æ®")
            kline = {
                'timestamp': pd.to_datetime(kline_data['t'], unit='ms'),
                'open': float(kline_data['o']),
                'high': float(kline_data['h']),
                'low': float(kline_data['l']),
                'close': float(kline_data['c']),
                'volume': float(kline_data['v'])
            }
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.kline_buffers[symbol].append(kline)
            updated_cache_count = len(self.kline_buffers[symbol])
            print(f"âœ… [æ•°æ®æ·»åŠ ] {symbol} æ–°Kçº¿å·²æ·»åŠ ï¼Œç¼“å­˜æ›´æ–°: {updated_cache_count}/{self.buffer_size} æ ¹")
            print(f"ğŸ“… [æ—¶é—´ä¿¡æ¯] {symbol} Kçº¿æ—¶é—´: {kline['timestamp']}, æ”¶ç›˜ä»·: {kline['close']:.6f}")
            
            # æ›´æ–°ç»Ÿè®¡è®¡æ•°
            self.message_count += 1
            print(f"ğŸ“Š [å¤„ç†ç»Ÿè®¡] å·²å¤„ç† {self.message_count} ä¸ªäº¤æ˜“å¯¹, æ£€æµ‹åˆ° {self.pattern_count} ä¸ªå½¢æ€, å‘é€äº† {self.signal_count} ä¸ªä¿¡å·")
            
            # è½¬æ¢ä¸ºDataFrame
            buffer_len = len(self.kline_buffers[symbol])
            # éœ€è¦è‡³å°‘100æ ¹Kçº¿è¿›è¡Œå½¢æ€è¯†åˆ«
            if buffer_len < 100:
                print(f"âš ï¸ [æ•°æ®ä¸è¶³] {symbol} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡åˆ†æ ({buffer_len}/100)")
                logger.debug(f"{symbol}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡åˆ†æ ({buffer_len}/100)")
                return
            
            print(f"âœ… [æ•°æ®å……è¶³] {symbol} æ•°æ®å……è¶³ï¼Œå¼€å§‹åˆ†æ {buffer_len} æ ¹Kçº¿")
            logger.info(f"{symbol} æ•°æ®å……è¶³ï¼Œå¼€å§‹åˆ†æ {buffer_len} æ ¹Kçº¿")
            
            # å®šæ—¶æ¨¡å¼ä¸‹ï¼Œè·å–çš„éƒ½æ˜¯å·²å®Œæˆçš„Kçº¿
            print(f"ğŸ“Š [Kçº¿å®Œæˆ] {symbol} ä»·æ ¼: {kline['close']:.4f}, æ—¶é—´: {kline['timestamp'].strftime('%Y-%m-%d %H:%M')}, ç¼“å­˜: {buffer_len}æ ¹")
            logger.debug(f"{symbol}: Kçº¿å®Œæˆï¼Œå¼€å§‹å½¢æ€æ£€æµ‹")
            
            # è½¬æ¢ä¸ºDataFrameï¼ˆä»…åœ¨éœ€è¦åˆ†ææ—¶ï¼‰
            print(f"ğŸ“ˆ [æ•°æ®è½¬æ¢] {symbol} è½¬æ¢ {buffer_len} æ ¹Kçº¿ä¸ºDataFrame...")
            df = pd.DataFrame(list(self.kline_buffers[symbol]))
            df.set_index('timestamp', inplace=True)
            
            # å…ˆè®¡ç®—å½¢æ€è¯†åˆ«å¿…éœ€çš„åŸºç¡€æŒ‡æ ‡ï¼ˆä»…ATRï¼‰
            print(f"âš¡ [åŸºç¡€æŒ‡æ ‡] {symbol} è®¡ç®—ATRæŒ‡æ ‡ (å‘¨æœŸ14)...")
            df = self.calculate_basic_indicators(df)
            
            # æ˜¾ç¤ºATRç»Ÿè®¡ä¿¡æ¯
            if 'atr' in df.columns and not df['atr'].isna().all():
                atr_current = df['atr'].iloc[-1]
                atr_avg = df['atr'].tail(20).mean()
                print(f"ğŸ“Š [ATRç»Ÿè®¡] {symbol} å½“å‰ATR: {atr_current:.6f}, 20å‘¨æœŸå‡å€¼: {atr_avg:.6f}")
            
            # è¿›è¡Œå½¢æ€æ£€æµ‹ï¼ˆåŸºäºATRï¼‰
            print(f"ğŸ” [å½¢æ€æ‰«æ] {symbol} æ‰«æåŒé¡¶åŒåº•å’Œå¤´è‚©å½¢æ€...")
            patterns = self.find_enhanced_patterns(df)
            
            if patterns:
                print(f"ğŸ¯ [å½¢æ€ç¡®è®¤] {symbol} å‘ç° {len(patterns)} ä¸ªå½¢æ€: {[p['type'] for p in patterns]}")
                logger.info(f"{symbol}: å‘ç° {len(patterns)} ä¸ªå½¢æ€")
                self.pattern_count += len(patterns)
                
                # åªæœ‰åœ¨å‘ç°å½¢æ€æ—¶æ‰è®¡ç®—å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰
                print(f"âš¡ [å®Œæ•´æŒ‡æ ‡] {symbol} è®¡ç®—EMA/MACD/RSI/æˆäº¤é‡æŒ‡æ ‡...")
                df = self.calculate_indicators(df)
                
                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡ä¿¡æ¯
                current_price = df['close'].iloc[-1]
                ema21 = df['ema21'].iloc[-1] if 'ema21' in df.columns else None
                ema55 = df['ema55'].iloc[-1] if 'ema55' in df.columns else None
                rsi = df['rsi'].iloc[-1] if 'rsi' in df.columns else None
                
                if ema21 and ema55 and rsi:
                    print(f"ğŸ“Š [æŠ€æœ¯æŒ‡æ ‡] {symbol} ä»·æ ¼: {current_price:.4f}, EMA21: {ema21:.4f}, EMA55: {ema55:.4f}, RSI: {rsi:.1f}")
                
                # ä¿¡å·åˆ†æ
                print(f"ğŸ”¬ [ä¿¡å·åˆ†æ] {symbol} å¼€å§‹åˆ†æ {len(patterns)} ä¸ªå½¢æ€ä¿¡å·")
                for i, pattern in enumerate(patterns, 1):
                    print(f"   ğŸ“‹ [ä¿¡å· {i}] ç±»å‹: {pattern['type']}, å¼ºåº¦: {pattern.get('strength', 'N/A')}")
                    print(f"ğŸš€ [ä¿¡å·åˆ†æ] {symbol} åˆ†æç¬¬{i}ä¸ªå½¢æ€: {pattern['type']}")
                    asyncio.create_task(self.analyze_pattern(symbol, df, pattern))
            else:
                print(f"â­• [å½¢æ€ç»“æœ] {symbol} æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å½¢æ€")
                logger.debug(f"{symbol}: æœªå‘ç°å½¢æ€")
            
            # å®šæ—¶æ¨¡å¼è¯´æ˜
            print(f"â° [å®šæ—¶æ¨¡å¼] {symbol} æœ¬æ¬¡åˆ†æå®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€å°æ—¶å®šæ—¶è§¦å‘")
                    
        except Exception as e:
            print(f"âŒ [é”™è¯¯] å¤„ç†Kçº¿æ•°æ®å¤±è´¥ {symbol}: {e}")
            logger.error(f"å¤„ç†Kçº¿æ•°æ®å¤±è´¥ {symbol}: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
    
    async def analyze_pattern(self, symbol: str, df: pd.DataFrame, pattern: Dict):
        """åˆ†æå½¢æ€å¹¶å‘é€ä¿¡å· - å®Œå…¨æŒ‰ç…§å›æµ‹è„šæœ¬é€»è¾‘"""
        try:
            pattern_idx = pattern['pattern_idx']
            
            print(f"\nğŸ”¬ [å½¢æ€åˆ†æ] {symbol} - {pattern['type']} (ä½ç½®: {pattern_idx})")
            logger.info(f"ğŸ” åˆ†æå½¢æ€: {symbol} - {pattern['type']} (ä½ç½®: {pattern_idx})")
            
            # è®¡ç®—æŒ‡æ ‡çŠ¶æ€
            print(f"ğŸ“ˆ [è¶‹åŠ¿åˆ†æ] {symbol} å¼€å§‹è¶‹åŠ¿åˆ†æ...")
            trend_status = self.check_trend_status(df, pattern_idx)
            print(f"ğŸ“Š [è¶‹åŠ¿ç»“æœ] {symbol} è¶‹åŠ¿çŠ¶æ€: {trend_status}")
            
            # èƒŒç¦»æ£€æŸ¥
            print(f"ğŸ” [èƒŒç¦»æ£€æµ‹] {symbol} å¼€å§‹èƒŒç¦»åˆ†æ...")
            macd_divergence = False
            rsi_divergence = False
            volume_divergence = False
            
            if pattern['type'] in ['double_top', 'double_bottom']:
                idx1, idx2 = pattern['idx1'], pattern['idx2']
                print(f"ğŸ“Š [åŒé¡¶åŒåº•] {symbol} æ£€æŸ¥ç´¢å¼• {idx1} å’Œ {idx2} ä¹‹é—´çš„èƒŒç¦»")
                macd_divergence = self.check_macd_divergence(df, pattern['type'], idx1, idx2)
                rsi_divergence = self.check_rsi_divergence(df, pattern['type'], idx1, idx2)
                volume_divergence = self.check_volume_divergence(df, pattern['type'], idx1, idx2)
            elif pattern['type'] in ['head_shoulder_top', 'head_shoulder_bottom']:
                # å¤´è‚©å½¢æ€ä½¿ç”¨å¤´éƒ¨å’Œå³è‚©è¿›è¡ŒèƒŒç¦»æ£€æŸ¥
                head_idx = pattern['head_idx']
                right_shoulder_idx = pattern['right_shoulder_idx']
                print(f"ğŸ“Š [å¤´è‚©å½¢æ€] {symbol} æ£€æŸ¥å¤´éƒ¨ç´¢å¼• {head_idx} å’Œå³è‚©ç´¢å¼• {right_shoulder_idx} ä¹‹é—´çš„èƒŒç¦»")
                macd_divergence = self.check_macd_divergence(df, pattern['type'], head_idx, right_shoulder_idx)
                rsi_divergence = self.check_rsi_divergence(df, pattern['type'], head_idx, right_shoulder_idx)
                volume_divergence = self.check_volume_divergence(df, pattern['type'], head_idx, right_shoulder_idx)
            
            print(f"ğŸ“Š [èƒŒç¦»ç»“æœ] {symbol} MACDèƒŒç¦»: {macd_divergence}, RSIèƒŒç¦»: {rsi_divergence}, æˆäº¤é‡èƒŒç¦»: {volume_divergence}")
            
            # èœ¡çƒ›å½¢æ€
            print(f"ğŸ•¯ï¸ [èœ¡çƒ›å½¢æ€] {symbol} å¼€å§‹èœ¡çƒ›å½¢æ€æ£€æµ‹...")
            candle_pattern = self.check_candle_pattern(df, pattern_idx)
            print(f"ğŸ•¯ï¸ [èœ¡çƒ›ç»“æœ] {symbol} èœ¡çƒ›å½¢æ€: {candle_pattern}")
            
            # åˆ›å»ºä¿¡å·æ•°æ®
            signal_price = df.iloc[pattern_idx]['close']
            signal_timestamp = df.index[pattern_idx]
            
            print(f"\nğŸš¨ [ä¿¡å·ç”Ÿæˆ] {symbol} å‡†å¤‡ç”Ÿæˆä¿¡å·:")
            print(f"   ğŸ“ å½¢æ€ç±»å‹: {pattern['type']}")
            print(f"   ğŸ’° ä¿¡å·ä»·æ ¼: {signal_price:.4f}")
            print(f"   â° ä¿¡å·æ—¶é—´: {signal_timestamp.strftime('%Y-%m-%d %H:%M')}")
            print(f"   ğŸ“ˆ è¶‹åŠ¿çŠ¶æ€: {trend_status}")
            print(f"   ğŸ“Š èƒŒç¦»æƒ…å†µ: MACD={macd_divergence}, RSI={rsi_divergence}, æˆäº¤é‡={volume_divergence}")
            print(f"   ğŸ•¯ï¸ èœ¡çƒ›å½¢æ€: {candle_pattern}")
            
            signal = SignalData(
                symbol=symbol,
                timestamp=signal_timestamp,
                price=signal_price,
                pattern_type=pattern['type'],
                trend_status=trend_status,
                macd_divergence=macd_divergence,
                rsi_divergence=rsi_divergence,
                volume_divergence=volume_divergence,
                candle_pattern=candle_pattern
            )
            
            print(f"âœ… [ä¿¡å·åˆ›å»º] {symbol} ä¿¡å·æ•°æ®åˆ›å»ºå®Œæˆ")
            logger.info(f"ğŸš¨ ç”Ÿæˆä¿¡å·: {symbol} - {pattern['type']} - ä»·æ ¼: {signal.price:.4f}")
            
            # ç›´æ¥å‘é€ä¿¡å·åˆ°webhookï¼ˆå·²åˆ é™¤ä¿¡å·éªŒè¯ï¼‰
            print(f"ğŸ“¤ [ä¿¡å·å‘é€] {symbol} å¼€å§‹å‘é€ä¿¡å·åˆ°webhook...")
            await self.send_signal_to_webhook(signal)
            print(f"ğŸ“¨ [å‘é€å®Œæˆ] {symbol} ä¿¡å·å‘é€æµç¨‹å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ [åˆ†æå¤±è´¥] {symbol} å½¢æ€åˆ†æå¤±è´¥: {e}")
            logger.error(f"åˆ†æå½¢æ€å¤±è´¥ {symbol}: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
    
    async def fetch_latest_klines(self):
        """è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„æœ€æ–°Kçº¿æ•°æ® - å¢é‡æ›´æ–°æ¨¡å¼"""
        print(f"ğŸ“Š [æ•°æ®è·å–] å¼€å§‹å¢é‡æ›´æ–° {len(self.active_symbols)} ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®")
        
        success_count = 0
        failed_count = 0
        
        for symbol in self.active_symbols:
            try:
                # æ£€æŸ¥ç¼“å­˜çŠ¶æ€ï¼Œå†³å®šè·å–ç­–ç•¥
                current_cache_size = len(self.kline_buffers.get(symbol, []))
                
                if current_cache_size >= self.buffer_size:
                    # ç¼“å­˜å·²æ»¡ï¼Œåªè·å–æœ€æ–°1æ ¹Kçº¿è¿›è¡Œå¢é‡æ›´æ–°
                    print(f"ğŸ”„ [å¢é‡æ›´æ–°] {symbol} ç¼“å­˜å·²æ»¡({current_cache_size}æ ¹)ï¼Œè·å–æœ€æ–°1æ ¹Kçº¿")
                    latest_klines = await self.get_historical_klines(symbol, 1)
                    update_mode = "incremental"
                else:
                    # ç¼“å­˜ä¸è¶³ï¼Œè·å–è¶³å¤Ÿçš„å†å²æ•°æ®
                    needed_klines = self.buffer_size - current_cache_size
                    print(f"ğŸ“ˆ [è¡¥å……æ•°æ®] {symbol} ç¼“å­˜ä¸è¶³({current_cache_size}æ ¹)ï¼Œè·å–{needed_klines}æ ¹Kçº¿")
                    latest_klines = await self.get_historical_klines(symbol, needed_klines)
                    update_mode = "fill"
                
                if latest_klines and len(latest_klines) > 0:
                    if update_mode == "incremental":
                        # å¢é‡æ›´æ–°ï¼šåªå¤„ç†æœ€æ–°çš„1æ ¹Kçº¿
                        latest_kline = latest_klines[0]
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ•°æ®ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
                        if symbol in self.kline_buffers and len(self.kline_buffers[symbol]) > 0:
                            last_cached_time = self.kline_buffers[symbol][-1]['timestamp']
                            new_kline_time = latest_kline['timestamp']
                            
                            if new_kline_time <= last_cached_time:
                                print(f"â­ï¸ [è·³è¿‡é‡å¤] {symbol} æœ€æ–°Kçº¿æ—¶é—´({new_kline_time})ä¸æ™šäºç¼“å­˜({last_cached_time})ï¼Œè·³è¿‡")
                                continue
                        
                        print(f"âœ¨ [å¢é‡æ·»åŠ ] {symbol} æ·»åŠ æ–°Kçº¿: {latest_kline['timestamp']} ä»·æ ¼: {latest_kline['close']:.6f}")
                        
                        # è½¬æ¢ä¸ºå¤„ç†æ ¼å¼
                        kline_data = {
                            's': symbol,
                            't': int(latest_kline['timestamp'].timestamp() * 1000),
                            'T': int(latest_kline['timestamp'].timestamp() * 1000) + 3600000,
                            'o': str(latest_kline['open']),
                            'h': str(latest_kline['high']),
                            'l': str(latest_kline['low']),
                            'c': str(latest_kline['close']),
                            'v': str(latest_kline['volume']),
                            'x': True
                        }
                        
                        # å¤„ç†å•æ ¹Kçº¿æ•°æ®ï¼ˆdequeä¼šè‡ªåŠ¨åˆ é™¤æœ€æ—§æ•°æ®ï¼‰
                        self.process_kline_data(symbol, kline_data)
                        
                    else:
                        # æ‰¹é‡å¡«å……æ¨¡å¼ï¼šå¤„ç†å¤šæ ¹Kçº¿
                        print(f"ğŸ“Š [æ‰¹é‡å¡«å……] {symbol} æ‰¹é‡æ·»åŠ {len(latest_klines)}æ ¹Kçº¿")
                        for kline in latest_klines:
                            kline_data = {
                                's': symbol,
                                't': int(kline['timestamp'].timestamp() * 1000),
                                'T': int(kline['timestamp'].timestamp() * 1000) + 3600000,
                                'o': str(kline['open']),
                                'h': str(kline['high']),
                                'l': str(kline['low']),
                                'c': str(kline['close']),
                                'v': str(kline['volume']),
                                'x': True
                            }
                            # åªæ·»åŠ åˆ°ç¼“å­˜ï¼Œä¸è¿›è¡Œåˆ†æï¼ˆé¿å…é‡å¤åˆ†æï¼‰
                            if symbol not in self.kline_buffers:
                                self.kline_buffers[symbol] = deque(maxlen=self.buffer_size)
                            
                            kline_dict = {
                                'timestamp': kline['timestamp'],
                                'open': kline['open'],
                                'high': kline['high'],
                                'low': kline['low'],
                                'close': kline['close'],
                                'volume': kline['volume']
                            }
                            self.kline_buffers[symbol].append(kline_dict)
                        
                        # æ‰¹é‡å¡«å……åï¼Œåªå¯¹æœ€æ–°Kçº¿è¿›è¡Œåˆ†æ
                        if len(latest_klines) > 0:
                            latest_kline = latest_klines[-1]  # æœ€æ–°çš„Kçº¿
                            kline_data = {
                                's': symbol,
                                't': int(latest_kline['timestamp'].timestamp() * 1000),
                                'T': int(latest_kline['timestamp'].timestamp() * 1000) + 3600000,
                                'o': str(latest_kline['open']),
                                'h': str(latest_kline['high']),
                                'l': str(latest_kline['low']),
                                'c': str(latest_kline['close']),
                                'v': str(latest_kline['volume']),
                                'x': True
                            }
                             # åªè¿›è¡Œåˆ†æï¼Œä¸é‡å¤æ·»åŠ åˆ°ç¼“å­˜
                    self.analyze_cached_data(symbol, kline_data)
                    
                    success_count += 1
                    
                else:
                    print(f"âš ï¸ [æ•°æ®è·å–] {symbol} æœªè·å–åˆ°Kçº¿æ•°æ®")
                    failed_count += 1
                    
            except Exception as e:
                print(f"âŒ [æ•°æ®è·å–] {symbol} è·å–å¤±è´¥: {str(e)}")
                failed_count += 1
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            await asyncio.sleep(0.2)  # 200mså»¶è¿Ÿ
        
        print(f"ğŸ“Š [æ•°æ®è·å–] å®Œæˆå¢é‡æ›´æ–° - æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
    
    def analyze_cached_data(self, symbol, kline_data):
        """åˆ†æç¼“å­˜æ•°æ®ï¼ˆç”¨äºæ‰¹é‡å¡«å……æ¨¡å¼ï¼‰"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¶³å¤Ÿ
            if symbol not in self.kline_buffers or len(self.kline_buffers[symbol]) < 50:
                print(f"âš ï¸ [åˆ†æè·³è¿‡] {symbol} ç¼“å­˜æ•°æ®ä¸è¶³({len(self.kline_buffers.get(symbol, []))}æ ¹)ï¼Œè·³è¿‡åˆ†æ")
                return
            
            # è½¬æ¢æ•°æ®æ ¼å¼
            df_data = []
            for kline in self.kline_buffers[symbol]:
                df_data.append({
                    'timestamp': kline['timestamp'],
                    'open': float(kline['open']),
                    'high': float(kline['high']),
                    'low': float(kline['low']),
                    'close': float(kline['close']),
                    'volume': float(kline['volume'])
                })
            
            df = pd.DataFrame(df_data)
            df.set_index('timestamp', inplace=True)
            
            print(f"ğŸ“ˆ [ç¼“å­˜åˆ†æ] {symbol} åŸºäº{len(df)}æ ¹Kçº¿è¿›è¡ŒæŠ€æœ¯åˆ†æ")
            
            # è®¡ç®—åŸºç¡€æŒ‡æ ‡
            basic_indicators = self.calculate_basic_indicators(df)
            if not basic_indicators:
                return
            
            # è®¡ç®—å®Œæ•´æŒ‡æ ‡
            indicators = self.calculate_indicators(df, basic_indicators)
            if not indicators:
                return
            
            # æ£€æµ‹å½¢æ€å’Œä¿¡å·
            patterns = self.detect_patterns(df, indicators)
            signals = self.analyze_signals(df, indicators, patterns)
            
            # è¾“å‡ºåˆ†æç»“æœ
            if signals:
                current_price = float(kline_data['c'])
                print(f"ğŸ¯ [ä¿¡å·æ£€æµ‹] {symbol} å½“å‰ä»·æ ¼: {current_price:.6f}")
                
                for signal in signals:
                    print(f"ğŸ“Š [æŠ€æœ¯ä¿¡å·] {symbol} - {signal['type']}: {signal['description']}")
                    if 'strength' in signal:
                        print(f"   å¼ºåº¦: {signal['strength']:.2f}")
                    
                    # å‘é€ä¿¡å·é€šçŸ¥
                    asyncio.create_task(self.send_signal(symbol, signal, current_price))
            
            # æ›´æ–°ç»Ÿè®¡
            self.processed_count += 1
            
        except Exception as e:
            print(f"âŒ [åˆ†æé”™è¯¯] {symbol} ç¼“å­˜åˆ†æå¤±è´¥: {str(e)}")
    

    
    async def start_monitoring(self):
        """å¼€å§‹ç›‘æ§ - å®šæ—¶è·å–æ¨¡å¼"""
        logger.info("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆå®šæ—¶ä¿¡å·ç›‘æ§...")
        
        # ä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨
        if IS_HF_SPACE:
            try:
                from hf_config import get_effective_symbols
                backup_symbols = get_effective_symbols()
            except ImportError:
                # ä½¿ç”¨é»˜è®¤å¤‡ç”¨åˆ—è¡¨
                backup_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT"]
        else:
            # æœ¬åœ°ç¯å¢ƒä½¿ç”¨é»˜è®¤åˆ—è¡¨
            backup_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT"]
            
        logger.info("ğŸ”„ ä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨")
        print("ğŸ”„ [å¯åŠ¨ç­–ç•¥] ä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨")
        logger.info(f"ğŸ“Š å¤‡ç”¨åˆ—è¡¨çŠ¶æ€: ä½¿ç”¨ {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
        print(f"ğŸ“Š [åˆ—è¡¨çŠ¶æ€] ä½¿ç”¨ {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
        
        self.active_symbols = set(backup_symbols)
        
        logger.info(f"ğŸ“¡ å°†ç›‘æ§ {len(self.active_symbols)} ä¸ªåŠ¨æ€å¤‡ç”¨äº¤æ˜“å¯¹")
        print(f"ğŸ“¡ [ç›‘æ§èŒƒå›´] å°†ç›‘æ§ {len(self.active_symbols)} ä¸ªåŠ¨æ€å¤‡ç”¨äº¤æ˜“å¯¹: {list(self.active_symbols)[:10]}{'...' if len(self.active_symbols) > 10 else ''}")
        
        # é¢„åŠ è½½å†å²æ•°æ®
        print("\nğŸš€ [ç›‘æ§å¯åŠ¨] å¼€å§‹é¢„åŠ è½½å†å²æ•°æ®...")
        logger.info("ğŸ“Š å¼€å§‹é¢„åŠ è½½å†å²æ•°æ®...")
        
        loaded_count = 0
        failed_count = 0
        accessible_symbols = set()  # è®°å½•å¯è®¿é—®çš„äº¤æ˜“å¯¹
        
        for symbol in self.active_symbols:
            print(f"ğŸ“Š [æ•°æ®åŠ è½½] æ­£åœ¨è·å– {symbol} å†å²æ•°æ®...")
            # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œå½¢æ€è¯†åˆ«ï¼ˆè‡³å°‘200æ ¹Kçº¿ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
            historical_data = await self.get_historical_klines(symbol, max(200, self.buffer_size))
            if historical_data:
                # åˆå§‹åŒ–æ•°æ®ç¼“å†²åŒºå¹¶å¡«å…¥å†å²æ•°æ®
                self.kline_buffers[symbol] = deque(historical_data, maxlen=self.buffer_size)
                accessible_symbols.add(symbol)  # è®°å½•å¯è®¿é—®çš„äº¤æ˜“å¯¹
                loaded_count += 1
                print(f"âœ… [æ•°æ®åŠ è½½] {symbol} é¢„åŠ è½½å®Œæˆ: {len(historical_data)} æ ¹Kçº¿")
                logger.info(f"âœ… {symbol} é¢„åŠ è½½å®Œæˆ: {len(historical_data)} æ ¹Kçº¿")
            else:
                # å¦‚æœæ— æ³•è·å–å†å²æ•°æ®ï¼Œä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤è¯¥äº¤æ˜“å¯¹
                failed_count += 1
                print(f"âŒ [æ•°æ®åŠ è½½] {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
                logger.warning(f"âš ï¸ {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            await asyncio.sleep(0.3)  # 300mså»¶è¿Ÿ
        
        # æ›´æ–°æ´»è·ƒäº¤æ˜“å¯¹åˆ—è¡¨ï¼Œåªä¿ç•™å¯è®¿é—®çš„äº¤æ˜“å¯¹
        self.active_symbols = accessible_symbols
        
        if not self.active_symbols:
            logger.error("âŒ æ‰€æœ‰å¤‡ç”¨äº¤æ˜“å¯¹éƒ½æ— æ³•è®¿é—®ï¼Œå¯èƒ½é‡åˆ°åœ°ç†é™åˆ¶")
            print("âŒ [ç›‘æ§æš‚åœ] æ‰€æœ‰å¤‡ç”¨äº¤æ˜“å¯¹éƒ½æ— æ³•è®¿é—®ï¼Œå¯èƒ½é‡åˆ°åœ°ç†é™åˆ¶")
            print("ğŸ’¡ [è§£å†³æ–¹æ¡ˆ] è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•:")
            print("   1. ä½¿ç”¨VPNè¿æ¥åˆ°æ”¯æŒçš„åœ°åŒº")
            print("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print("   3. ç­‰å¾…ç½‘ç»œç¯å¢ƒæ”¹å–„åé‡è¯•")
            print("â³ [è‡ªåŠ¨é‡è¯•] ç¨‹åºå°†åœ¨5åˆ†é’Ÿåè‡ªåŠ¨é‡è¯•...")
            
            # ç­‰å¾…5åˆ†é’Ÿåé‡è¯•
            await asyncio.sleep(300)
            print("ğŸ”„ [é‡æ–°å°è¯•] å¼€å§‹é‡æ–°è·å–äº¤æ˜“å¯¹åˆ—è¡¨...")
            
            # é‡æ–°è·å–å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨
            if IS_HF_SPACE:
                try:
                    from hf_config import get_effective_symbols
                    backup_symbols = get_effective_symbols()
                    logger.info(f"HFç¯å¢ƒ: ä½¿ç”¨get_effective_symbolsè·å–åˆ° {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
                except ImportError:
                    backup_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT', 'SOLUSDT', 'DOTUSDT', 'DOGEUSDT', 'AVAXUSDT', 'SHIBUSDT', 'LTCUSDT', 'MATICUSDT', 'TRXUSDT', 'WBTCUSDT', 'DAIUSDT', 'LINKUSDT', 'ATOMUSDT', 'ETCUSDT', 'XLMUSDT', 'BCHUSDT', 'FILUSDT', 'ICPUSDT', 'APTUSDT', 'NEARUSDT', 'VETUSDT', 'ALGOUSDT', 'FLOWUSDT', 'HBARUSDT', 'QNTUSDT', 'MANAUSDT', 'SANDUSDT', 'AXSUSDT', 'THETAUSDT', 'XTZUSDT', 'EGLDUSDT', 'AAVEUSDT', 'EOSUSDT', 'KLAYUSDT', 'FTMUSDT', 'GRTUSDT', 'CHZUSDT', 'MKRUSDT', 'NEOUSDT', 'BTTUSDT', 'KSMUSDT', 'AMPUSDT', 'WAVESUSDT', 'ZILUSDT', 'BATUSDT', 'ZECUSDT', 'DASHUSDT', 'ENJUSDT', 'COMPUSDT', 'YFIUSDT', 'SNXUSDT', 'UMAUSDT', 'BALUSDT', 'CRVUSDT', 'SUSHIUSDT', 'RENUSDT', 'KNCUSDT', 'LRCUSDT', 'BANDUSDT', 'STORJUSDT', 'CTKUSDT', 'OCEANUSDT', 'NMRUSDT', 'RSRUSDT', 'KAVAUSDT', 'IOTAUSDT', 'ONTUSDT', 'ZILUSDT', 'FETUSDT', 'CELRUSDT', 'TFUELUSDT', 'ONEUSDT', 'HOTUSDT', 'WINUSDT', 'DUSKUSDT', 'COSUSDT', 'COCOSUSDT', 'MTLUSDT', 'TOMOUSDT', 'PERUSDT', 'NKNUSDT', 'DGBUSDT', 'OGNUSDT', 'LSKUSDT', 'WANUSDT', 'FUNUSDT', 'CVCUSDT', 'CHRUSDT', 'BANDUSDT', 'BUSDUSDT', 'BELUSDT', 'WINGUSDT', 'CREAMUSDT', 'UNIUSDT', 'NBSUSDT', 'OXTUSDT', 'SUNUSDT', 'AVAXUSDT', 'HNTUSDT', 'FLMUSDT', 'UTKUSDT', 'XVSUSDT', 'ALPHABUSDT', 'VIDTUSDT', 'AUCTIONUSDT', 'C98USDT', 'MASKUSDT', 'LPTUSDT', 'NUUSDT', 'XVGUSDT', 'ATALUSDT', 'GTCUSDT', 'TORNUSDT', 'KEEPUSDT', 'ERNUSDT', 'KLAYUSDT', 'PHAUSDT', 'BONDUSDT', 'MLNUSDT', 'DEXEUSDT', 'C98USDT', 'CLVUSDT', 'QNTUSDT', 'FLOWUSDT', 'TVKUSDT', 'BADGERUSDT', 'FISUSDT', 'OMGUSDT', 'PONDUSDT', 'DEGOUSDT', 'ALICEUSDT', 'LINAUSDT', 'PERPUSDT', 'RAMPUSDT', 'SUPERUSDT', 'CFXUSDT', 'EPSUSDT', 'AUTOUSDT', 'TKOUSDT', 'PUNDIXUSDT', 'TLMUSDT', 'BTCSTUSDT', 'BARUSDT', 'FORTHUSDT', 'BAKEUSDT', 'BURGERUSDT', 'SLPUSDT', 'SHIBUSDT', 'ICPUSDT', 'ARUSDT', 'POLSUSDT', 'MDXUSDT', 'MASKUSDT', 'LPTUSDT', 'NUUSDT', 'XVGUSDT', 'ATALUSDT', 'GTCUSDT', 'TORNUSDT', 'KEEPUSDT', 'ERNUSDT', 'KLAYUSDT', 'PHAUSDT', 'BONDUSDT', 'MLNUSDT', 'DEXEUSDT', 'C98USDT', 'CLVUSDT', 'QNTUSDT', 'FLOWUSDT', 'TVKUSDT', 'BADGERUSDT', 'FISUSDT', 'OMGUSDT', 'PONDUSDT', 'DEGOUSDT', 'ALICEUSDT', 'LINAUSDT', 'PERPUSDT', 'RAMPUSDT', 'SUPERUSDT', 'CFXUSDT', 'EPSUSDT', 'AUTOUSDT', 'TKOUSDT', 'PUNDIXUSDT', 'TLMUSDT', 'BTCSTUSDT', 'BARUSDT', 'FORTHUSDT', 'BAKEUSDT', 'BURGERUSDT', 'SLPUSDT']
                    logger.info(f"HFç¯å¢ƒ: å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤‡ç”¨åˆ—è¡¨ {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
            else:
                backup_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT', 'SOLUSDT', 'DOTUSDT', 'DOGEUSDT', 'AVAXUSDT', 'SHIBUSDT', 'LTCUSDT', 'MATICUSDT', 'TRXUSDT', 'WBTCUSDT', 'DAIUSDT', 'LINKUSDT', 'ATOMUSDT', 'ETCUSDT', 'XLMUSDT', 'BCHUSDT', 'FILUSDT', 'ICPUSDT', 'APTUSDT', 'NEARUSDT', 'VETUSDT', 'ALGOUSDT', 'FLOWUSDT', 'HBARUSDT', 'QNTUSDT', 'MANAUSDT', 'SANDUSDT', 'AXSUSDT', 'THETAUSDT', 'XTZUSDT', 'EGLDUSDT', 'AAVEUSDT', 'EOSUSDT', 'KLAYUSDT', 'FTMUSDT', 'GRTUSDT', 'CHZUSDT', 'MKRUSDT', 'NEOUSDT', 'BTTUSDT', 'KSMUSDT', 'AMPUSDT', 'WAVESUSDT', 'ZILUSDT', 'BATUSDT', 'ZECUSDT', 'DASHUSDT', 'ENJUSDT', 'COMPUSDT', 'YFIUSDT', 'SNXUSDT', 'UMAUSDT', 'BALUSDT', 'CRVUSDT', 'SUSHIUSDT', 'RENUSDT', 'KNCUSDT', 'LRCUSDT', 'BANDUSDT', 'STORJUSDT', 'CTKUSDT', 'OCEANUSDT', 'NMRUSDT', 'RSRUSDT', 'KAVAUSDT', 'IOTAUSDT', 'ONTUSDT', 'ZILUSDT', 'FETUSDT', 'CELRUSDT', 'TFUELUSDT', 'ONEUSDT', 'HOTUSDT', 'WINUSDT', 'DUSKUSDT', 'COSUSDT', 'COCOSUSDT', 'MTLUSDT', 'TOMOUSDT', 'PERUSDT', 'NKNUSDT', 'DGBUSDT', 'OGNUSDT', 'LSKUSDT', 'WANUSDT', 'FUNUSDT', 'CVCUSDT', 'CHRUSDT', 'BANDUSDT', 'BUSDUSDT', 'BELUSDT', 'WINGUSDT', 'CREAMUSDT', 'UNIUSDT', 'NBSUSDT', 'OXTUSDT', 'SUNUSDT', 'AVAXUSDT', 'HNTUSDT', 'FLMUSDT', 'UTKUSDT', 'XVSUSDT', 'ALPHABUSDT', 'VIDTUSDT', 'AUCTIONUSDT', 'C98USDT', 'MASKUSDT', 'LPTUSDT', 'NUUSDT', 'XVGUSDT', 'ATALUSDT', 'GTCUSDT', 'TORNUSDT', 'KEEPUSDT', 'ERNUSDT', 'KLAYUSDT', 'PHAUSDT', 'BONDUSDT', 'MLNUSDT', 'DEXEUSDT', 'C98USDT', 'CLVUSDT', 'QNTUSDT', 'FLOWUSDT', 'TVKUSDT', 'BADGERUSDT', 'FISUSDT', 'OMGUSDT', 'PONDUSDT', 'DEGOUSDT', 'ALICEUSDT', 'LINAUSDT', 'PERPUSDT', 'RAMPUSDT', 'SUPERUSDT', 'CFXUSDT', 'EPSUSDT', 'AUTOUSDT', 'TKOUSDT', 'PUNDIXUSDT', 'TLMUSDT', 'BTCSTUSDT', 'BARUSDT', 'FORTHUSDT', 'BAKEUSDT', 'BURGERUSDT', 'SLPUSDT', 'SHIBUSDT', 'ICPUSDT', 'ARUSDT', 'POLSUSDT', 'MDXUSDT', 'MASKUSDT', 'LPTUSDT', 'NUUSDT', 'XVGUSDT', 'ATALUSDT', 'GTCUSDT', 'TORNUSDT', 'KEEPUSDT', 'ERNUSDT', 'KLAYUSDT', 'PHAUSDT', 'BONDUSDT', 'MLNUSDT', 'DEXEUSDT', 'C98USDT', 'CLVUSDT', 'QNTUSDT', 'FLOWUSDT', 'TVKUSDT', 'BADGERUSDT', 'FISUSDT', 'OMGUSDT', 'PONDUSDT', 'DEGOUSDT', 'ALICEUSDT', 'LINAUSDT', 'PERPUSDT', 'RAMPUSDT', 'SUPERUSDT', 'CFXUSDT', 'EPSUSDT', 'AUTOUSDT', 'TKOUSDT', 'PUNDIXUSDT', 'TLMUSDT', 'BTCSTUSDT', 'BARUSDT', 'FORTHUSDT', 'BAKEUSDT', 'BURGERUSDT', 'SLPUSDT']
                logger.info(f"æœ¬åœ°ç¯å¢ƒ: ä½¿ç”¨é»˜è®¤å¤‡ç”¨åˆ—è¡¨ {len(backup_symbols)} ä¸ªäº¤æ˜“å¯¹")
            
            # é‡æ–°å°è¯•é¢„åŠ è½½å†å²æ•°æ®
            print(f"ğŸ”„ [é‡æ–°é¢„åŠ è½½] å¼€å§‹é‡æ–°é¢„åŠ è½½å†å²æ•°æ®...")
            accessible_symbols = set()
            loaded_count = 0
            failed_count = 0
            
            for symbol in backup_symbols:
                try:
                    print(f"ğŸ“Š [æ•°æ®åŠ è½½] æ­£åœ¨è·å– {symbol} å†å²æ•°æ®...")
                    klines = await self.get_historical_klines(symbol, self.buffer_size)
                    if klines:
                        self.kline_buffers[symbol] = deque(maxlen=self.buffer_size)
                        for kline in klines:
                            self.kline_buffers[symbol].append(kline)
                        accessible_symbols.add(symbol)
                        loaded_count += 1
                        print(f"âœ… [æ•°æ®åŠ è½½] {symbol} å†å²æ•°æ®åŠ è½½æˆåŠŸ")
                        logger.info(f"âœ… {symbol} å†å²æ•°æ®åŠ è½½æˆåŠŸ")
                    else:
                        failed_count += 1
                        print(f"âŒ [æ•°æ®åŠ è½½] {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
                        logger.warning(f"âš ï¸ {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
                except Exception as e:
                    failed_count += 1
                    print(f"âŒ [æ•°æ®åŠ è½½] {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
                    logger.warning(f"âš ï¸ {symbol} å†å²æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»ç›‘æ§åˆ—è¡¨ç§»é™¤")
            
            # æ›´æ–°æ´»è·ƒäº¤æ˜“å¯¹åˆ—è¡¨
            self.active_symbols = accessible_symbols
            
            if not self.active_symbols:
                logger.error("âŒ é‡è¯•åä»ç„¶æ— æ³•è®¿é—®ä»»ä½•äº¤æ˜“å¯¹ï¼Œç›‘æ§æ— æ³•ç»§ç»­")
                print("âŒ [ç›‘æ§ç»ˆæ­¢] é‡è¯•åä»ç„¶æ— æ³•è®¿é—®ä»»ä½•äº¤æ˜“å¯¹ï¼Œç›‘æ§æ— æ³•ç»§ç»­")
                print("ğŸ’¡ [æœ€ç»ˆå»ºè®®] è¯·ç¡®ä¿ç½‘ç»œç¯å¢ƒæ”¯æŒè®¿é—®å¸å®‰APIï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")
                return
        
        print(f"\nğŸ“ˆ [æ•°æ®ç»Ÿè®¡] é¢„åŠ è½½å®Œæˆ: æˆåŠŸ {loaded_count} ä¸ª, å¤±è´¥ {failed_count} ä¸ª")
        print(f"ğŸ¯ [é¢„åŠ è½½å®Œæˆ] å†å²æ•°æ®é¢„åŠ è½½å®Œæˆï¼Œå°†ç›‘æ§ {len(self.active_symbols)} ä¸ªå¯è®¿é—®çš„äº¤æ˜“å¯¹ï¼")
        print(f"ğŸ“‹ [ç›‘æ§åˆ—è¡¨] {list(self.active_symbols)[:10]}{'...' if len(self.active_symbols) > 10 else ''}")
        
        logger.info(f"ğŸ¯ å†å²æ•°æ®é¢„åŠ è½½å®Œæˆï¼Œå¼€å§‹å®šæ—¶ç›‘æ§æ¨¡å¼ï¼")
        
        # å®šæ—¶ç›‘æ§å¾ªç¯ - æ¯å°æ—¶çš„ç¬¬ä¸€åˆ†é’Ÿè·å–æ•°æ®
        print(f"\nâ° [å®šæ—¶ç›‘æ§] å¯åŠ¨å®šæ—¶ç›‘æ§æ¨¡å¼ (1å°æ—¶å‘¨æœŸ)")
        print(f"ğŸ“… [ç›‘æ§è¯´æ˜] æ¯å°æ—¶ç¬¬1åˆ†é’Ÿè·å–ä¸Šä¸€æ ¹å®Œæ•´Kçº¿æ•°æ®")
        
        while True:
            try:
                current_time = datetime.now()
                current_minute = current_time.minute
                
                # æ¯å°æ—¶çš„ç¬¬ä¸€åˆ†é’Ÿæ‰§è¡Œæ•°æ®è·å–å’Œåˆ†æ
                if current_minute == 0:
                    print(f"\nğŸ• [å®šæ—¶è§¦å‘] {current_time.strftime('%Y-%m-%d %H:%M:%S')} - å¼€å§‹è·å–Kçº¿æ•°æ®")
                    logger.info(f"å®šæ—¶è§¦å‘: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    
                    # è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„æœ€æ–°Kçº¿æ•°æ®
                    await self.fetch_latest_klines_api()
                    
                    # ç­‰å¾…åˆ°ä¸‹ä¸€åˆ†é’Ÿï¼Œé¿å…é‡å¤è§¦å‘
                    print(f"â³ [ç­‰å¾…ä¸‹æ¬¡] ç­‰å¾…åˆ°ä¸‹ä¸€å°æ—¶çš„ç¬¬1åˆ†é’Ÿ...")
                    await asyncio.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ
                else:
                    # è®¡ç®—åˆ°ä¸‹ä¸€å°æ—¶ç¬¬1åˆ†é’Ÿçš„ç­‰å¾…æ—¶é—´
                    minutes_to_wait = 60 - current_minute
                    if minutes_to_wait > 1:
                        print(f"â° [ç­‰å¾…ä¸­] å½“å‰æ—¶é—´ {current_time.strftime('%H:%M')}, {minutes_to_wait} åˆ†é’Ÿåå¼€å§‹ä¸‹æ¬¡æ£€æŸ¥")
                        await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                    else:
                        await asyncio.sleep(10)  # æ¥è¿‘è§¦å‘æ—¶é—´æ—¶æ›´é¢‘ç¹æ£€æŸ¥
                        
            except Exception as e:
                print(f"âŒ [ç›‘æ§å¼‚å¸¸] å®šæ—¶ç›‘æ§å‡ºç°å¼‚å¸¸: {e}")
                logger.error(f"å®šæ—¶ç›‘æ§å¼‚å¸¸: {e}")
                logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                print(f"â³ [å¼‚å¸¸æ¢å¤] 60ç§’åç»§ç»­ç›‘æ§...")
                await asyncio.sleep(60)
    
    async def fetch_latest_klines_api(self):
        """é€šè¿‡è®¤è¯APIè·å–æœ€æ–°Kçº¿æ•°æ®å¹¶è¿›è¡Œä¿¡å·æ£€æµ‹"""
        try:
            print(f"ğŸ“Š [APIè·å–] å¼€å§‹è·å– {len(self.active_symbols)} ä¸ªäº¤æ˜“å¯¹çš„æœ€æ–°Kçº¿æ•°æ®...")
            
            processed_count = 0
            signal_count = 0
            
            for symbol in self.active_symbols:
                try:
                    # ä½¿ç”¨è®¤è¯APIè·å–æœ€æ–°çš„Kçº¿æ•°æ®
                    latest_klines = await self._make_authenticated_request(
                        '/fapi/v1/klines',
                        {
                            'symbol': symbol,
                            'interval': '1h',
                            'limit': 2  # è·å–æœ€æ–°çš„2æ ¹Kçº¿
                        }
                    )
                    
                    if not latest_klines or len(latest_klines) < 2:
                        logger.warning(f"âš ï¸ {symbol} APIè¿”å›æ•°æ®ä¸è¶³")
                        continue
                    
                    # å–å€’æ•°ç¬¬äºŒæ ¹Kçº¿ï¼ˆå·²å®Œæˆçš„Kçº¿ï¼‰
                    completed_kline = latest_klines[-2]
                    
                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    kline_data = {
                        'open_time': int(completed_kline[0]),
                        'open': float(completed_kline[1]),
                        'high': float(completed_kline[2]),
                        'low': float(completed_kline[3]),
                        'close': float(completed_kline[4]),
                        'volume': float(completed_kline[5]),
                        'close_time': int(completed_kline[6]),
                        'quote_volume': float(completed_kline[7]),
                        'count': int(completed_kline[8])
                    }
                    
                    # æ›´æ–°Kçº¿ç¼“å­˜
                    if symbol not in self.kline_buffers:
                        self.kline_buffers[symbol] = deque(maxlen=self.buffer_size)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„Kçº¿æ•°æ®
                    if (not self.kline_buffers[symbol] or 
                        self.kline_buffers[symbol][-1]['open_time'] != kline_data['open_time']):
                        
                        self.kline_buffers[symbol].append(kline_data)
                        processed_count += 1
                        
                        # è¿›è¡Œä¿¡å·æ£€æµ‹
                        if await self.process_kline_data(symbol, kline_data):
                            signal_count += 1
                        
                        logger.debug(f"âœ… {symbol} Kçº¿æ•°æ®å·²æ›´æ–°")
                    else:
                        logger.debug(f"â„¹ï¸ {symbol} Kçº¿æ•°æ®æ— å˜åŒ–")
                        
                except Exception as e:
                    logger.error(f"âŒ {symbol} APIè·å–å¤±è´¥: {e}")
                    continue
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(0.2)  # 200mså»¶è¿Ÿ
            
            print(f"ğŸ“ˆ [APIå®Œæˆ] å¤„ç†å®Œæˆ: {processed_count} ä¸ªäº¤æ˜“å¯¹æœ‰æ–°æ•°æ®, {signal_count} ä¸ªä¿¡å·")
            logger.info(f"APIæ•°æ®è·å–å®Œæˆ: å¤„ç† {processed_count} ä¸ªäº¤æ˜“å¯¹, å‘ç° {signal_count} ä¸ªä¿¡å·")
            
        except Exception as e:
            logger.error(f"APIè·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            print(f"âŒ [APIå¼‚å¸¸] Kçº¿æ•°æ®è·å–å¤±è´¥: {e}")
    
    async def manual_update_symbols(self) -> bool:
        """æ‰‹åŠ¨æ›´æ–°äº¤æ˜“å¯¹åˆ—è¡¨ - å·²ç§»é™¤symbol_updateråŠŸèƒ½"""
        logger.info("â„¹ï¸ æ‰‹åŠ¨æ›´æ–°åŠŸèƒ½å·²ç§»é™¤ï¼Œä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨")
        print("â„¹ï¸ [æç¤º] æ‰‹åŠ¨æ›´æ–°åŠŸèƒ½å·²ç§»é™¤ï¼Œä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨")
        return True
    
    def get_symbol_status(self) -> Dict:
        """è·å–äº¤æ˜“å¯¹çŠ¶æ€ä¿¡æ¯"""
        # ä½¿ç”¨å›ºå®šçš„å¤‡ç”¨äº¤æ˜“å¯¹åˆ—è¡¨
        if IS_HF_SPACE:
            try:
                from hf_config import get_effective_symbols
                current_symbols = get_effective_symbols()[:100]
            except ImportError:
                current_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'SOLUSDT']
        else:
            current_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'SOLUSDT']
        
        return {
            'current_symbols': current_symbols,
            'symbol_count': len(current_symbols),
            'updater_status': 'Symbol updater removed - using fixed backup list',
            'monitoring_active': len(self.active_symbols) > 0 if hasattr(self, 'active_symbols') else False
        }

if __name__ == "__main__":
    # ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è·å–é…ç½®
    import os
    from dotenv import load_dotenv
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    WEBHOOK_URL = os.getenv('WEBHOOK_URL', 'https://your-webhook-url.com/signal')
    
    # APIå¯†é’¥é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
    API_KEY = os.getenv('API_KEY')
    API_SECRET = os.getenv('API_SECRET')
    
    if not API_KEY or not API_SECRET:
        print("âŒ [é…ç½®é”™è¯¯] APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®API_KEYå’ŒAPI_SECRET")
        logger.error("APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•å¯åŠ¨ç›‘æ§")
        exit(1)
    
    # åˆ›å»ºç›‘æ§å®ä¾‹ï¼ˆä½¿ç”¨APIæ¨¡å¼ï¼‰
    monitor = EnhancedRealTimeMonitor(WEBHOOK_URL, api_key=API_KEY, api_secret=API_SECRET)
    
    print("ğŸš€ [å¯åŠ¨æ¨¡å¼] ä½¿ç”¨å¸å®‰è®¤è¯APIå®šæœŸè·å–æ•°æ®")
    print(f"ğŸ”‘ [APIé…ç½®] API Key: {API_KEY[:8]}...")
    print("ğŸ“Š [æ•°æ®æ¨¡å¼] æ¯å°æ—¶è·å–ä¸€æ¬¡å®Œæ•´Kçº¿æ•°æ®")
    
    # å¯åŠ¨ç›‘æ§
    try:
        asyncio.run(monitor.start_monitoring())
    except KeyboardInterrupt:
        logger.info("ç›‘æ§å·²åœæ­¢")
        print("\nğŸ‘‹ [ç¨‹åºé€€å‡º] ç›‘æ§å·²æ‰‹åŠ¨åœæ­¢")